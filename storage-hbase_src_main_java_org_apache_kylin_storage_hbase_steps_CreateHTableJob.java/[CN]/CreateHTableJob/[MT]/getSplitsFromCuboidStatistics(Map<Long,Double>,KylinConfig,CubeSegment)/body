{
  final CubeDesc cubeDesc=cubeSegment.getCubeDesc();
  DataModelDesc.RealizationCapacity cubeCapacity=cubeDesc.getModel().getCapacity();
  int cut=kylinConfig.getHBaseRegionCut(cubeCapacity.toString());
  logger.info("Cube capacity " + cubeCapacity.toString() + ", chosen cut for HTable is "+ cut+ "GB");
  double totalSizeInM=0;
  for (  Double cuboidSize : cubeSizeMap.values()) {
    totalSizeInM+=cuboidSize;
  }
  List<Long> allCuboids=Lists.newArrayList();
  allCuboids.addAll(cubeSizeMap.keySet());
  Collections.sort(allCuboids);
  int nRegion=Math.round((float)(totalSizeInM / (cut * 1024L)));
  nRegion=Math.max(kylinConfig.getHBaseRegionCountMin(),nRegion);
  nRegion=Math.min(kylinConfig.getHBaseRegionCountMax(),nRegion);
  if (cubeSegment.isEnableSharding()) {
    int original=nRegion;
    nRegion=Primes.nextPrime(nRegion);
    if (nRegion > Short.MAX_VALUE) {
      logger.info("Too many regions! reduce to " + Short.MAX_VALUE);
      nRegion=Short.MAX_VALUE;
    }
    if (nRegion != original) {
      logger.info("Region count is adjusted from " + original + " to "+ nRegion+ " to help random sharding");
    }
  }
  int mbPerRegion=(int)(totalSizeInM / nRegion);
  mbPerRegion=Math.max(1,mbPerRegion);
  logger.info("Total size " + totalSizeInM + "M (estimated)");
  logger.info("Expecting " + nRegion + " regions.");
  logger.info("Expecting " + mbPerRegion + " MB per region.");
  if (cubeSegment.isEnableSharding()) {
    HashMap<Long,Short> cuboidShards=Maps.newHashMap();
    double[] regionSizes=new double[nRegion];
    for (    long cuboidId : allCuboids) {
      double estimatedSize=cubeSizeMap.get(cuboidId);
      double magic=23;
      int shardNum=(int)(estimatedSize * magic / mbPerRegion + 1);
      if (shardNum < 1) {
        shardNum=1;
      }
      if (shardNum > nRegion) {
        logger.info(String.format("Cuboid %d 's estimated size %.2f MB will generate %d regions, reduce to %d",cuboidId,estimatedSize,shardNum,nRegion));
        shardNum=nRegion;
      }
 else {
        logger.info(String.format("Cuboid %d 's estimated size %.2f MB will generate %d regions",cuboidId,estimatedSize,shardNum));
      }
      cuboidShards.put(cuboidId,(short)shardNum);
      short startShard=ShardingHash.getShard(cuboidId,nRegion);
      for (short i=startShard; i < startShard + shardNum; ++i) {
        short j=(short)(i % nRegion);
        regionSizes[j]=regionSizes[j] + estimatedSize / shardNum;
      }
    }
    for (int i=0; i < nRegion; ++i) {
      logger.info(String.format("Region %d's estimated size is %.2f MB, accounting for %.2f percent",i,regionSizes[i],100.0 * regionSizes[i] / totalSizeInM));
    }
    CuboidShardUtil.saveCuboidShards(cubeSegment,cuboidShards,nRegion);
    return getSplitsByRegionCount(nRegion);
  }
 else {
    List<Long> regionSplit=Lists.newArrayList();
    long size=0;
    int regionIndex=0;
    int cuboidCount=0;
    for (int i=0; i < allCuboids.size(); i++) {
      long cuboidId=allCuboids.get(i);
      if (size >= mbPerRegion || (size + cubeSizeMap.get(cuboidId)) >= mbPerRegion * 1.2) {
        regionSplit.add(cuboidId);
        logger.info("Region " + regionIndex + " will be "+ size+ " MB, contains cuboids < "+ cuboidId+ " ("+ cuboidCount+ ") cuboids");
        size=0;
        cuboidCount=0;
        regionIndex++;
      }
      size+=cubeSizeMap.get(cuboidId);
      cuboidCount++;
    }
    byte[][] result=new byte[regionSplit.size()][];
    for (int i=0; i < regionSplit.size(); i++) {
      result[i]=Bytes.toBytes(regionSplit.get(i));
    }
    return result;
  }
}
