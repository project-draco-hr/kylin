{
  CubeDesc cubeDesc=cubeSegment.getCubeDesc();
  DataModelDesc.RealizationCapacity cubeCapacity=cubeDesc.getModel().getCapacity();
  int cut=kylinConfig.getHBaseRegionCut(cubeCapacity.toString());
  logger.info("Cube capacity " + cubeCapacity.toString() + ", chosen cut for HTable is "+ cut+ "GB");
  Map<Long,Long> cuboidSizeMap=Maps.newHashMap();
  long totalSizeInM=0;
  ResourceStore rs=ResourceStore.getStore(kylinConfig);
  String fileKey=cubeSegment.getStatisticsResourcePath();
  InputStream is=rs.getResource(fileKey);
  File tempFile=null;
  FileOutputStream tempFileStream=null;
  try {
    tempFile=File.createTempFile(cubeSegment.getUuid(),".seq");
    tempFileStream=new FileOutputStream(tempFile);
    org.apache.commons.io.IOUtils.copy(is,tempFileStream);
  }
  finally {
    IOUtils.closeStream(is);
    IOUtils.closeStream(tempFileStream);
  }
  FileSystem fs=HadoopUtil.getFileSystem("file:///" + tempFile.getAbsolutePath());
  SequenceFile.Reader reader=null;
  try {
    reader=new SequenceFile.Reader(fs,new Path(tempFile.getAbsolutePath()),conf);
    LongWritable key=(LongWritable)ReflectionUtils.newInstance(reader.getKeyClass(),conf);
    BytesWritable value=(BytesWritable)ReflectionUtils.newInstance(reader.getValueClass(),conf);
    int samplingPercentage=25;
    while (reader.next(key,value)) {
      if (key.get() == 0l) {
        samplingPercentage=Bytes.toInt(value.getBytes());
      }
 else {
        HyperLogLogPlusCounter hll=new HyperLogLogPlusCounter(14);
        ByteArray byteArray=new ByteArray(value.getBytes());
        hll.readRegisters(byteArray.asBuffer());
        cuboidSizeMap.put(key.get(),hll.getCountEstimate() * 100 / samplingPercentage);
      }
    }
  }
 catch (  Exception e) {
    e.printStackTrace();
    throw e;
  }
 finally {
    IOUtils.closeStream(reader);
  }
  List<Long> allCuboids=Lists.newArrayList();
  allCuboids.addAll(cuboidSizeMap.keySet());
  Collections.sort(allCuboids);
  long baseCuboidId=Cuboid.getBaseCuboidId(cubeDesc);
  for (  long cuboidId : allCuboids) {
    long cuboidSize=estimateCuboidStorageSize(cubeDesc,cuboidId,cuboidSizeMap.get(cuboidId),baseCuboidId,rowkeyColumnSize);
    cuboidSizeMap.put(cuboidId,cuboidSize);
    totalSizeInM+=cuboidSize;
  }
  int nRegion=Math.round((float)totalSizeInM / ((float)cut * 1024l));
  nRegion=Math.max(kylinConfig.getHBaseRegionCutMin(),nRegion);
  nRegion=Math.min(kylinConfig.getHBaseRegionCutMax(),nRegion);
  int mbPerRegion=(int)(totalSizeInM / (nRegion));
  mbPerRegion=Math.max(1,mbPerRegion);
  logger.info("Total size " + totalSizeInM + "M (estimated)");
  logger.info(nRegion + " regions (estimated)");
  logger.info(mbPerRegion + " MB per region (estimated)");
  List<Long> regionSplit=Lists.newArrayList();
  long size=0;
  int regionIndex=0;
  int cuboidCount=0;
  for (int i=0; i < allCuboids.size(); i++) {
    long cuboidId=allCuboids.get(i);
    if (size >= mbPerRegion || (size + cuboidSizeMap.get(cuboidId)) >= mbPerRegion * 1.2) {
      regionSplit.add(cuboidId);
      logger.info("Region " + regionIndex + " will be "+ size+ " MB, contains cuboids < "+ cuboidId+ " ("+ cuboidCount+ ") cuboids");
      size=0;
      cuboidCount=0;
      regionIndex++;
    }
    size+=cuboidSizeMap.get(cuboidId);
    cuboidCount++;
  }
  byte[][] result=new byte[regionSplit.size()][];
  for (int i=0; i < regionSplit.size(); i++) {
    result[i]=Bytes.toBytes(regionSplit.get(i));
  }
  return result;
}
