{
  String jarPath=kylinConf.getKylinJobJarPath();
  File jarFile=new File(jarPath);
  if (jarFile.exists()) {
    job.setJar(jarPath);
    logger.info("append job jar: " + jarPath);
  }
 else {
    job.setJarByClass(this.getClass());
  }
  String kylinHiveDependency=System.getProperty("kylin.hive.dependency");
  String kylinHBaseDependency=System.getProperty("kylin.hbase.dependency");
  String kylinKafkaDependency=System.getProperty("kylin.kafka.dependency");
  logger.info("append kylin.hbase.dependency: " + kylinHBaseDependency + " to "+ MAP_REDUCE_CLASSPATH);
  Configuration jobConf=job.getConfiguration();
  String classpath=jobConf.get(MAP_REDUCE_CLASSPATH);
  if (classpath == null || classpath.length() == 0) {
    logger.info("Didn't find " + MAP_REDUCE_CLASSPATH + " in job configuration, will run 'mapred classpath' to get the default value.");
    classpath=getDefaultMapRedClasspath();
    logger.info("The default mapred classpath is: " + classpath);
  }
  if (kylinHBaseDependency != null) {
    kylinHBaseDependency=kylinHBaseDependency.replace(":",",");
    classpath=classpath + "," + kylinHBaseDependency;
  }
  jobConf.set(MAP_REDUCE_CLASSPATH,classpath);
  logger.info("Hadoop job classpath is: " + job.getConfiguration().get(MAP_REDUCE_CLASSPATH));
  StringBuilder kylinDependency=new StringBuilder();
  if (kylinHiveDependency != null) {
    kylinHiveDependency=kylinHiveDependency.replace(":",",");
    logger.info("Hive Dependencies Before Filtered: " + kylinHiveDependency);
    String filteredHive=filterKylinHiveDependency(kylinHiveDependency);
    logger.info("Hive Dependencies After Filtered: " + filteredHive);
    if (kylinDependency.length() > 0)     kylinDependency.append(",");
    kylinDependency.append(filteredHive);
  }
 else {
    logger.info("No hive dependency jars set in the environment, will find them from jvm:");
    try {
      String hiveExecJarPath=ClassUtil.findContainingJar(Class.forName("org.apache.hadoop.hive.ql.Driver"));
      kylinDependency.append(hiveExecJarPath).append(",");
      logger.info("hive-exec jar file: " + hiveExecJarPath);
      String hiveHCatJarPath=ClassUtil.findContainingJar(Class.forName("org.apache.hive.hcatalog.mapreduce.HCatInputFormat"));
      kylinDependency.append(hiveHCatJarPath).append(",");
      logger.info("hive-catalog jar file: " + hiveHCatJarPath);
      String hiveMetaStoreJarPath=ClassUtil.findContainingJar(Class.forName("org.apache.hadoop.hive.metastore.api.Table"));
      kylinDependency.append(hiveMetaStoreJarPath).append(",");
      logger.info("hive-metastore jar file: " + hiveMetaStoreJarPath);
    }
 catch (    ClassNotFoundException e) {
      logger.error("Cannot found hive dependency jars: " + e);
    }
  }
  if (kylinKafkaDependency != null) {
    kylinKafkaDependency=kylinKafkaDependency.replace(":",",");
    logger.info("Kafka Dependencies Before Filtered: " + kylinKafkaDependency);
    if (kylinDependency.length() > 0)     kylinDependency.append(",");
    kylinDependency.append(kylinKafkaDependency);
  }
 else {
    logger.info("No Kafka dependency jars set in the environment, will find them from jvm:");
    try {
      String kafkaClientJarPath=ClassUtil.findContainingJar(Class.forName("org.apache.kafka.clients.consumer.KafkaConsumer"));
      kylinDependency.append(kafkaClientJarPath).append(",");
      logger.info("kafka jar file: " + kafkaClientJarPath);
    }
 catch (    ClassNotFoundException e) {
      logger.error("Cannot found kafka dependency jars: " + e);
    }
  }
  String mrLibDir=kylinConf.getKylinJobMRLibDir();
  if (!StringUtils.isBlank(mrLibDir)) {
    if (kylinDependency.length() > 0) {
      kylinDependency.append(",");
    }
    kylinDependency.append(mrLibDir);
  }
  setJobTmpJarsAndFiles(job,kylinDependency.toString());
  overrideJobConfig(job.getConfiguration(),kylinConf.getMRConfigOverride());
}
