{
  if (microStreamBatch.size() == 0) {
    logger.info("nothing to build, skip to next iteration after sleeping 10s");
    Thread.sleep(10000);
    return;
  }
 else {
    logger.info("Consuming {} messages, covering from {} to {}",new String[]{String.valueOf(microStreamBatch.size()),DateFormat.formatToTimeStr(microStreamBatch.getTimestamp().getFirst()),DateFormat.formatToTimeStr(microStreamBatch.getTimestamp().getSecond())});
  }
  totalConsumedMessageCount+=microStreamBatch.size();
  totalRawMessageCount+=microStreamBatch.getRawMessageCount();
  final List<List<String>> parsedStreamMessages=microStreamBatch.getStreams();
  long startOffset=microStreamBatch.getOffset().getFirst();
  long endOffset=microStreamBatch.getOffset().getSecond();
  LinkedBlockingQueue<List<String>> blockingQueue=new LinkedBlockingQueue<List<String>>(parsedStreamMessages);
  blockingQueue.put(Collections.<String>emptyList());
  final CubeInstance cubeInstance=cubeManager.reloadCubeLocal(cubeName);
  final CubeDesc cubeDesc=cubeInstance.getDescriptor();
  final CubeSegment cubeSegment=cubeManager.appendSegments(cubeManager.getCube(cubeName),microStreamBatch.getTimestamp().getSecond(),false,false);
  final Map<Long,HyperLogLogPlusCounter> samplingResult=sampling(cubeInstance.getDescriptor(),parsedStreamMessages);
  final Configuration conf=HadoopUtil.getCurrentConfiguration();
  final Path outputPath=new Path("file:///tmp/cuboidstatistics/" + UUID.randomUUID().toString());
  FactDistinctColumnsReducer.writeCuboidStatistics(conf,outputPath,samplingResult,100);
  ResourceStore.getStore(kylinConfig).putResource(cubeSegment.getStatisticsResourcePath(),FileSystem.getLocal(conf).open(new Path(outputPath,BatchConstants.CFG_STATISTICS_CUBOID_ESTIMATION)),0);
  final Map<TblColRef,Dictionary<?>> dictionaryMap=buildDictionary(cubeInstance,parsedStreamMessages);
  writeDictionary(cubeSegment,dictionaryMap,startOffset,endOffset);
  final HTableInterface hTable=createHTable(cubeSegment);
  final CubeStreamRecordWriter gtRecordWriter=new CubeStreamRecordWriter(cubeDesc,hTable);
  InMemCubeBuilder inMemCubeBuilder=new InMemCubeBuilder(blockingQueue,cubeInstance.getDescriptor(),dictionaryMap,gtRecordWriter);
  executorService.submit(inMemCubeBuilder).get();
  gtRecordWriter.flush();
  commitSegment(cubeSegment);
  logger.info("Consumed {} messages out of {} raw messages",totalConsumedMessageCount,totalRawMessageCount);
}
