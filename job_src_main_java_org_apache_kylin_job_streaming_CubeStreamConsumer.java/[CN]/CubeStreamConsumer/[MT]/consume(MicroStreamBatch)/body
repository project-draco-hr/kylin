{
  totalConsumedMessageCount+=microStreamBatch.size();
  totalRawMessageCount+=microStreamBatch.getRawMessageCount();
  final List<List<String>> parsedStreamMessages=microStreamBatch.getStreams();
  long startOffset=microStreamBatch.getOffset().getFirst();
  long endOffset=microStreamBatch.getOffset().getSecond();
  LinkedBlockingQueue<List<String>> blockingQueue=new LinkedBlockingQueue<List<String>>(parsedStreamMessages);
  blockingQueue.put(Collections.<String>emptyList());
  final CubeInstance cubeInstance=cubeManager.reloadCubeLocal(cubeName);
  final CubeDesc cubeDesc=cubeInstance.getDescriptor();
  final CubeSegment cubeSegment=cubeManager.appendSegments(cubeManager.getCube(cubeName),microStreamBatch.getTimestamp().getFirst(),microStreamBatch.getTimestamp().getSecond(),false,false);
  long start=System.currentTimeMillis();
  final Map<Long,HyperLogLogPlusCounter> samplingResult=CubingUtils.sampling(cubeInstance.getDescriptor(),parsedStreamMessages);
  logger.info(String.format("sampling of %d messages cost %d ms",parsedStreamMessages.size(),(System.currentTimeMillis() - start)));
  final Configuration conf=HadoopUtil.getCurrentConfiguration();
  final Path outputPath=new Path("file:///tmp/cuboidstatistics/" + UUID.randomUUID().toString());
  FileSystem.getLocal(conf).deleteOnExit(outputPath);
  FactDistinctColumnsReducer.writeCuboidStatistics(conf,outputPath,samplingResult,100);
  FSDataInputStream localStream=FileSystem.getLocal(conf).open(new Path(outputPath,BatchConstants.CFG_STATISTICS_CUBOID_ESTIMATION));
  ResourceStore.getStore(kylinConfig).putResource(cubeSegment.getStatisticsResourcePath(),localStream,0);
  localStream.close();
  final Map<TblColRef,Dictionary<?>> dictionaryMap=CubingUtils.buildDictionary(cubeInstance,parsedStreamMessages);
  Map<TblColRef,Dictionary<?>> realDictMap=writeDictionary(cubeSegment,dictionaryMap,startOffset,endOffset);
  InMemCubeBuilder inMemCubeBuilder=new InMemCubeBuilder(cubeInstance.getDescriptor(),realDictMap);
  final HTableInterface hTable=createHTable(cubeSegment);
  final CubeStreamRecordWriter gtRecordWriter=new CubeStreamRecordWriter(cubeDesc,hTable);
  executorService.submit(inMemCubeBuilder.buildAsRunnable(blockingQueue,gtRecordWriter)).get();
  gtRecordWriter.flush();
  hTable.close();
  commitSegment(cubeSegment);
  logger.info("Consumed {} messages out of {} raw messages",totalConsumedMessageCount,totalRawMessageCount);
}
