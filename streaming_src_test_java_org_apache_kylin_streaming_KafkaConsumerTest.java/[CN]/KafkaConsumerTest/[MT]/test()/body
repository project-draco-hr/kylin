{
  final TopicMeta kafkaTopicMeta=KafkaRequester.getKafkaTopicMeta(kafkaConfig);
  final ExecutorService executorService=Executors.newFixedThreadPool(kafkaTopicMeta.getPartitionIds().size());
  List<BlockingQueue<Stream>> queues=Lists.newArrayList();
  for (  Integer partitionId : kafkaTopicMeta.getPartitionIds()) {
    KafkaConsumer consumer=new KafkaConsumer(kafkaTopicMeta.getName(),partitionId,0,kafkaConfig.getBrokers(),kafkaConfig){
      @Override protected void consume(      long offset,      ByteBuffer payload) throws Exception {
        byte[] bytes=new byte[payload.limit()];
        payload.get(bytes);
        logger.info("get message offset:" + offset);
        getStreamQueue().put(new Stream(offset,bytes));
      }
    }
;
    queues.add(consumer.getStreamQueue());
    executorService.execute(consumer);
  }
  waitForProducerToStop(producer);
  Thread.sleep(5000);
  int count=0;
  for (  BlockingQueue<Stream> queue : queues) {
    count+=queue.size();
  }
  logger.info("count of messages are " + count);
  assertTrue(count >= TOTAL_SEND_COUNT && (count % TOTAL_SEND_COUNT == 0));
}
