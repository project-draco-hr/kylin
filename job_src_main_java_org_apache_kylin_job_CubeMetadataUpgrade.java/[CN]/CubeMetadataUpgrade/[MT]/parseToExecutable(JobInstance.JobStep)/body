{
  AbstractExecutable result;
switch (step.getCmdType()) {
case SHELL_CMD_HADOOP:
{
      ShellExecutable executable=new ShellExecutable();
      executable.setCmd(step.getExecCmd());
      result=executable;
      break;
    }
case JAVA_CMD_HADOOP_FACTDISTINCT:
{
    MapReduceExecutable executable=new MapReduceExecutable();
    executable.setMapReduceJobClass(FactDistinctColumnsJob.class);
    executable.setMapReduceParams(step.getExecCmd());
    result=executable;
    break;
  }
case JAVA_CMD_HADOOP_BASECUBOID:
{
  MapReduceExecutable executable=new MapReduceExecutable();
  executable.setMapReduceJobClass(BaseCuboidJob.class);
  executable.setMapReduceParams(step.getExecCmd());
  result=executable;
  break;
}
case JAVA_CMD_HADOOP_NDCUBOID:
{
MapReduceExecutable executable=new MapReduceExecutable();
executable.setMapReduceJobClass(NDCuboidJob.class);
executable.setMapReduceParams(step.getExecCmd());
result=executable;
break;
}
case JAVA_CMD_HADOOP_RANGEKEYDISTRIBUTION:
{
MapReduceExecutable executable=new MapReduceExecutable();
executable.setMapReduceJobClass(RangeKeyDistributionJob.class);
executable.setMapReduceParams(step.getExecCmd());
result=executable;
break;
}
case JAVA_CMD_HADOOP_CONVERTHFILE:
{
MapReduceExecutable executable=new MapReduceExecutable();
executable.setMapReduceJobClass(CubeHFileJob.class);
executable.setMapReduceParams(step.getExecCmd());
result=executable;
break;
}
case JAVA_CMD_HADOOP_MERGECUBOID:
{
MapReduceExecutable executable=new MapReduceExecutable();
executable.setMapReduceJobClass(MergeCuboidJob.class);
executable.setMapReduceParams(step.getExecCmd());
result=executable;
break;
}
case JAVA_CMD_HADOOP_NO_MR_DICTIONARY:
{
HadoopShellExecutable executable=new HadoopShellExecutable();
executable.setName(ExecutableConstants.STEP_NAME_BUILD_DICTIONARY);
executable.setJobClass(CreateDictionaryJob.class);
executable.setJobParams(step.getExecCmd());
result=executable;
break;
}
case JAVA_CMD_HADDOP_NO_MR_CREATEHTABLE:
{
HadoopShellExecutable executable=new HadoopShellExecutable();
executable.setJobClass(CreateHTableJob.class);
executable.setJobParams(step.getExecCmd());
result=executable;
break;
}
case JAVA_CMD_HADOOP_NO_MR_BULKLOAD:
{
HadoopShellExecutable executable=new HadoopShellExecutable();
executable.setJobClass(BulkLoadJob.class);
executable.setJobParams(step.getExecCmd());
result=executable;
break;
}
default :
throw new RuntimeException("invalid step type:" + step.getCmdType());
}
result.setName(step.getName());
return result;
}
