{
  Map<String,Set<String>> db2tables=Maps.newHashMap();
  for (  String table : hiveTables) {
    String[] dbtableNames=HadoopUtil.parseHiveTableName(table);
    Set<String> set=db2tables.get(dbtableNames[0]);
    if (set == null) {
      set=Sets.newHashSet();
      db2tables.put(dbtableNames[0],set);
    }
    set.add(dbtableNames[1]);
  }
  File metaTmpDir=File.createTempFile("meta_tmp",null);
  metaTmpDir.delete();
  metaTmpDir.mkdirs();
  for (  String database : db2tables.keySet()) {
    for (    String table : db2tables.get(database)) {
      TableDesc tableDesc=MetadataManager.getInstance(config).getTableDesc(table);
      if (tableDesc == null) {
        continue;
      }
      if (tableDesc.getDatabase().equalsIgnoreCase(database)) {
        continue;
      }
 else {
        throw new UnsupportedOperationException(String.format("there is already a table[%s] in database[%s]",tableDesc.getName(),tableDesc.getDatabase()));
      }
    }
  }
  Set<String> loadedTables=Sets.newHashSet();
  for (  String database : db2tables.keySet()) {
    List<String> loaded=extractHiveTables(database,db2tables.get(database),metaTmpDir,config);
    loadedTables.addAll(loaded);
  }
  ResourceTool.copy(KylinConfig.createInstanceFromUri(metaTmpDir.getAbsolutePath()),config);
  return loadedTables;
}
