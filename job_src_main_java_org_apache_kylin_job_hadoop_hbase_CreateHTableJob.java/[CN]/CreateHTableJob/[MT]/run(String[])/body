{
  Options options=new Options();
  options.addOption(OPTION_CUBE_NAME);
  options.addOption(OPTION_PARTITION_FILE_PATH);
  options.addOption(OPTION_HTABLE_NAME);
  parseOptions(options,args);
  Path partitionFilePath=new Path(getOptionValue(OPTION_PARTITION_FILE_PATH));
  String cubeName=getOptionValue(OPTION_CUBE_NAME).toUpperCase();
  KylinConfig config=KylinConfig.getInstanceFromEnv();
  CubeManager cubeMgr=CubeManager.getInstance(config);
  CubeInstance cube=cubeMgr.getCube(cubeName);
  CubeDesc cubeDesc=cube.getDescriptor();
  String tableName=getOptionValue(OPTION_HTABLE_NAME).toUpperCase();
  HTableDescriptor tableDesc=new HTableDescriptor(TableName.valueOf(tableName));
  tableDesc.setValue(HTableDescriptor.SPLIT_POLICY,ConstantSizeRegionSplitPolicy.class.getName());
  tableDesc.setValue(IRealizationConstants.HTableTag,config.getMetadataUrlPrefix());
  Configuration conf=HadoopUtil.getCurrentHBaseConfiguration();
  HBaseAdmin admin=new HBaseAdmin(conf);
  try {
    if (User.isHBaseSecurityEnabled(conf)) {
      tableDesc.addCoprocessor("org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint");
    }
    for (    HBaseColumnFamilyDesc cfDesc : cubeDesc.getHBaseMapping().getColumnFamily()) {
      HColumnDescriptor cf=new HColumnDescriptor(cfDesc.getName());
      cf.setMaxVersions(1);
      KylinConfig kylinConfig=KylinConfig.getInstanceFromEnv();
      String hbaseDefaultCC=kylinConfig.getHbaseDefaultCompressionCodec().toLowerCase();
switch (hbaseDefaultCC) {
case "snappy":
{
          logger.info("hbase will use snappy to compress data");
          cf.setCompressionType(Algorithm.SNAPPY);
          break;
        }
case "lzo":
{
        logger.info("hbase will use lzo to compress data");
        cf.setCompressionType(Algorithm.LZO);
        break;
      }
case "gz":
case "gzip":
{
      logger.info("hbase will use gzip to compress data");
      cf.setCompressionType(Algorithm.GZ);
      break;
    }
case "lz4":
{
    logger.info("hbase will use lz4 to compress data");
    cf.setCompressionType(Algorithm.LZ4);
    break;
  }
default :
{
  logger.info("hbase will not user any compression codec to compress data");
}
}
cf.setDataBlockEncoding(DataBlockEncoding.FAST_DIFF);
cf.setInMemory(false);
cf.setBlocksize(4 * 1024 * 1024);
tableDesc.addFamily(cf);
}
byte[][] splitKeys=getSplits(conf,partitionFilePath);
if (admin.tableExists(tableName)) {
throw new RuntimeException("HBase table " + tableName + " exists!");
}
DeployCoprocessorCLI.deployCoprocessor(tableDesc);
admin.createTable(tableDesc,splitKeys);
logger.info("create hbase table " + tableName + " done.");
return 0;
}
 catch (Exception e) {
printUsage(options);
e.printStackTrace(System.err);
logger.error(e.getLocalizedMessage(),e);
return 2;
}
 finally {
admin.close();
}
}
