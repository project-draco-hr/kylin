{
  final String mapReduceJobClass=getJobClass();
  String params=getJobParams();
  Preconditions.checkNotNull(mapReduceJobClass);
  Preconditions.checkNotNull(params);
  try {
    final Constructor<? extends AbstractHadoopJob> constructor=(Constructor<? extends AbstractHadoopJob>)Class.forName(mapReduceJobClass).getConstructor();
    final AbstractHadoopJob job=constructor.newInstance();
    String[] args=params.trim().split("\\s+");
    logger.info("parameters of the HadoopShellExecutable:");
    logger.info(params);
    int result;
    StringBuilder log=new StringBuilder();
    try {
      result=ToolRunner.run(job,args);
    }
 catch (    Exception ex) {
      logger.error("error execute " + this.toString(),ex);
      StringWriter stringWriter=new StringWriter();
      ex.printStackTrace(new PrintWriter(stringWriter));
      log.append(stringWriter.toString()).append("\n");
      result=2;
    }
    log.append("result code:").append(result);
    return result == 0 ? new ExecuteResult(ExecuteResult.State.SUCCEED,log.toString()) : new ExecuteResult(ExecuteResult.State.FAILED,log.toString());
  }
 catch (  ReflectiveOperationException e) {
    logger.error("error getMapReduceJobClass, class name:" + getParam(KEY_MR_JOB),e);
    return new ExecuteResult(ExecuteResult.State.ERROR,e.getLocalizedMessage());
  }
catch (  Exception e) {
    logger.error("error execute " + this.toString(),e);
    return new ExecuteResult(ExecuteResult.State.ERROR,e.getLocalizedMessage());
  }
}
