{
  try {
    final int inputCount=streamMessageQueues.size();
    final ExecutorService executorService=Executors.newFixedThreadPool(inputCount);
    long start=startTimestamp;
    List<Integer> partitions=Lists.newArrayList();
    for (int i=0, partitionCount=streamMessageQueues.size(); i < partitionCount; i++) {
      partitions.add(i);
    }
    while (true) {
      CountDownLatch countDownLatch=new CountDownLatch(inputCount);
      ArrayList<Future<MicroStreamBatch>> futures=Lists.newArrayListWithExpectedSize(inputCount);
      int partitionId=0;
      for (      BlockingQueue<StreamMessage> streamMessageQueue : streamMessageQueues) {
        futures.add(executorService.submit(new StreamFetcher(partitionId++,streamMessageQueue,countDownLatch,generateBatchCondition(start))));
      }
      countDownLatch.await();
      ArrayList<MicroStreamBatch> batches=Lists.newArrayListWithExpectedSize(inputCount);
      for (      Future<MicroStreamBatch> future : futures) {
        if (future.get() != null) {
          batches.add(future.get());
        }
 else {
          consumer.stop();
          return;
        }
      }
      MicroStreamBatch batch=batches.get(0);
      if (batches.size() > 1) {
        for (int i=1; i < inputCount; i++) {
          batch=MicroStreamBatch.union(batch,batches.get(i));
        }
      }
      if (batchInterval > 0) {
        start+=batchInterval;
      }
      if (batch.size() == 0) {
        logger.info("nothing to build, skip to next iteration after sleeping 10s");
        Thread.sleep(10000);
        continue;
      }
 else {
        logger.info("Consuming {} messages, covering from {} to {}",new String[]{String.valueOf(batch.size()),DateFormat.formatToTimeStr(batch.getTimestamp().getFirst()),DateFormat.formatToTimeStr(batch.getTimestamp().getSecond())});
        long startTime=System.currentTimeMillis();
        consumer.consume(batch);
        logger.info("Batch build costs {} milliseconds",System.currentTimeMillis() - startTime);
        if (batches.size() > 1) {
          final HashMap<Integer,Long> offset=Maps.newHashMap();
          for (          MicroStreamBatch microStreamBatch : batches) {
            offset.put(microStreamBatch.getPartitionId(),microStreamBatch.getOffset().getSecond());
          }
          StreamingManager.getInstance(KylinConfig.getInstanceFromEnv()).updateOffset(streaming,offset);
        }
      }
    }
  }
 catch (  InterruptedException e) {
    throw new RuntimeException("stream fetcher thread should not be interrupted",e);
  }
catch (  ExecutionException e) {
    logger.error("stream fetch thread encountered exception",e);
    throw new RuntimeException("stream fetch thread encountered exception",e);
  }
catch (  Exception e) {
    logger.error("consumer encountered exception",e);
    throw new RuntimeException("consumer encountered exception",e);
  }
}
