{
  super.publishConfiguration(context.getConfiguration());
  Configuration conf=context.getConfiguration();
  KylinConfig config=AbstractHadoopJob.loadKylinPropsAndMetadata(conf);
  cubeName=conf.get(BatchConstants.CFG_CUBE_NAME);
  cube=CubeManager.getInstance(config).getCube(cubeName);
  cubeDesc=cube.getDescriptor();
  intermediateTableDesc=new CubeJoinedFlatTableDesc(cubeDesc,null);
  long baseCuboidId=Cuboid.getBaseCuboidId(cubeDesc);
  Cuboid baseCuboid=Cuboid.findById(cubeDesc,baseCuboidId);
  List<TblColRef> columns=baseCuboid.getColumns();
  ArrayList<Integer> factDictCols=new ArrayList<Integer>();
  RowKeyDesc rowkey=cubeDesc.getRowkey();
  DictionaryManager dictMgr=DictionaryManager.getInstance(config);
  for (int i=0; i < columns.size(); i++) {
    TblColRef col=columns.get(i);
    if (rowkey.isUseDictionary(col) == false)     continue;
    String scanTable=(String)dictMgr.decideSourceData(cubeDesc.getModel(),cubeDesc.getRowkey().getDictionary(col),col,null)[0];
    if (cubeDesc.getModel().isFactTable(scanTable)) {
      factDictCols.add(i);
    }
  }
  this.factDictCols=new int[factDictCols.size()];
  for (int i=0; i < factDictCols.size(); i++)   this.factDictCols[i]=factDictCols.get(i);
  schema=HCatInputFormat.getTableSchema(context.getConfiguration());
}
