{
  Options options=new Options();
  try {
    options.addOption(OPTION_TABLE);
    options.addOption(OPTION_OUTPUT_PATH);
    parseOptions(options,args);
    String jobName=JOB_TITLE + getOptionsAsString();
    System.out.println("Starting: " + jobName);
    Configuration conf=getConf();
    job=Job.getInstance(conf,jobName);
    if (jarPath == null || !new File(jarPath).exists()) {
      job.setJarByClass(getClass());
    }
 else {
      job.setJar(jarPath);
    }
    Path output=new Path(getOptionValue(OPTION_OUTPUT_PATH));
    FileOutputFormat.setOutputPath(job,output);
    job.getConfiguration().set("dfs.block.size","67108864");
    this.table=getOptionValue(OPTION_TABLE);
    System.out.println("Going to start HiveColumnCardinalityJob on table '" + table + "'");
    HCatInputFormat.setInput(job,"default",table);
    System.out.println("Set input format as HCat on table '" + table + "'");
    HCatSchema tableSchema=HCatInputFormat.getTableSchema(job.getConfiguration());
    job.getConfiguration().set(KEY_TABLE_COLUMN_NUMBER,String.valueOf(tableSchema.size()));
    job.setInputFormatClass(HCatInputFormat.class);
    job.setMapperClass(ColumnCardinalityMapper.class);
    job.setMapOutputKeyClass(IntWritable.class);
    job.setMapOutputValueClass(BytesWritable.class);
    job.setReducerClass(ColumnCardinalityReducer.class);
    job.setOutputFormatClass(TextOutputFormat.class);
    job.setOutputKeyClass(IntWritable.class);
    job.setOutputValueClass(LongWritable.class);
    job.setNumReduceTasks(1);
    this.deletePath(job.getConfiguration(),output);
    isAsync=true;
    System.out.println("Going to submit HiveColumnCardinalityJob for table '" + table + "'");
    int result=waitForCompletion(job);
    System.out.println("Get job track url " + job.getJobID() + "\n");
    System.out.println("Get job track url " + job.getTrackingURL() + "\n");
    return result;
  }
 catch (  Exception e) {
    printUsage(options);
    e.printStackTrace(System.err);
    log.error(e.getLocalizedMessage(),e);
    return 2;
  }
}
