{
  final IIInstance ii=IIManager.getInstance(this.kylinConfig).getII(kafkaConfig.getIiName());
  Preconditions.checkNotNull(ii,"cannot find ii name:" + kafkaConfig.getIiName());
  Preconditions.checkArgument(ii.getSegments().size() > 0);
  final IISegment iiSegment=ii.getSegments().get(0);
  final Broker leadBroker=getLeadBroker(kafkaConfig,partitionId);
  Preconditions.checkState(leadBroker != null,"cannot find lead broker");
  final int shard=ii.getDescriptor().getSharding();
  Preconditions.checkArgument(shard % partitionCount == 0);
  final int parallelism=shard / partitionCount;
  final int startShard=partitionId * parallelism;
  final int endShard=startShard + parallelism;
  long streamingOffset=getEarliestStreamingOffset(kafkaConfig.getName(),startShard,endShard);
  streamingOffset=streamingOffset - (streamingOffset % parallelism);
  logger.info("offset from ii desc is " + streamingOffset);
  final long earliestOffset=KafkaRequester.getLastOffset(kafkaConfig.getTopic(),partitionId,OffsetRequest.EarliestTime(),leadBroker,kafkaConfig);
  logger.info("offset from KafkaRequester is " + earliestOffset);
  streamingOffset=Math.max(streamingOffset,earliestOffset);
  logger.info("starting offset is " + streamingOffset);
  if (!HBaseConnection.tableExists(kylinConfig.getStorageUrl(),iiSegment.getStorageLocationIdentifier())) {
    logger.error("no htable:" + iiSegment.getStorageLocationIdentifier() + " found");
    throw new IllegalStateException("please create htable:" + iiSegment.getStorageLocationIdentifier() + " first");
  }
  KafkaConsumer consumer=new KafkaConsumer(kafkaConfig.getTopic(),partitionId,streamingOffset,kafkaConfig.getBrokers(),kafkaConfig,parallelism);
  kafkaConsumers.put(getKey(kafkaConfig.getName(),partitionId),consumer);
  Executors.newSingleThreadExecutor().submit(consumer);
  final ExecutorService streamingBuilderPool=Executors.newFixedThreadPool(parallelism);
  for (int i=startShard; i < endShard; ++i) {
    final IIStreamBuilder task=new IIStreamBuilder(consumer.getStreamQueue(i % parallelism),kafkaConfig.getName(),iiSegment.getStorageLocationIdentifier(),iiSegment.getIIDesc(),i);
    task.setStreamParser(getStreamParser(kafkaConfig,ii.getDescriptor().listAllColumns()));
    if (i == endShard - 1) {
      streamingBuilderPool.submit(task).get();
    }
 else {
      streamingBuilderPool.submit(task);
    }
  }
}
