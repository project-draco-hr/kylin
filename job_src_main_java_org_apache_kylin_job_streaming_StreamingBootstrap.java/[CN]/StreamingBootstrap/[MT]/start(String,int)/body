{
  final KafkaConfig kafkaConfig=streamingManager.getKafkaConfig(streaming);
  Preconditions.checkArgument(kafkaConfig != null,"cannot find kafka config:" + streaming);
  final IIInstance ii=iiManager.getII(kafkaConfig.getIiName());
  Preconditions.checkNotNull(ii,"cannot find ii name:" + kafkaConfig.getIiName());
  final int partitionCount=KafkaRequester.getKafkaTopicMeta(kafkaConfig).getPartitionIds().size();
  Preconditions.checkArgument(partitionId >= 0 && partitionId < partitionCount,"invalid partition id:" + partitionId);
  Preconditions.checkArgument(ii.getSegments().size() > 0);
  final IISegment iiSegment=ii.getSegments().get(0);
  final Broker leadBroker=getLeadBroker(kafkaConfig,partitionId);
  Preconditions.checkState(leadBroker != null,"cannot find lead broker");
  final int shard=ii.getDescriptor().getSharding();
  Preconditions.checkArgument(shard % partitionCount == 0);
  final int parallelism=shard / partitionCount;
  final int startShard=partitionId * parallelism;
  final int endShard=startShard + parallelism;
  long streamingOffset=getEarliestStreamingOffset(streaming,startShard,endShard);
  streamingOffset=streamingOffset - (streamingOffset % parallelism);
  logger.info("offset from ii desc is " + streamingOffset);
  final long earliestOffset=KafkaRequester.getLastOffset(kafkaConfig.getTopic(),partitionId,OffsetRequest.EarliestTime(),leadBroker,kafkaConfig);
  logger.info("offset from KafkaRequester is " + earliestOffset);
  streamingOffset=Math.max(streamingOffset,earliestOffset);
  logger.info("starting offset is " + streamingOffset);
  IICreateHTableJob.main(new String[]{"-iiname","nous_ii","-htablename","KYLIN_2SKJ8JNOUS"});
  KafkaConsumer consumer=new KafkaConsumer(kafkaConfig.getTopic(),partitionId,streamingOffset,kafkaConfig.getBrokers(),kafkaConfig,parallelism);
  kafkaConsumers.put(getKey(streaming,partitionId),consumer);
  StreamParser parser;
  if (!StringUtils.isEmpty(kafkaConfig.getParserName())) {
    Class clazz=Class.forName(kafkaConfig.getParserName());
    Constructor constructor=clazz.getConstructor(List.class);
    parser=(StreamParser)constructor.newInstance(ii.getDescriptor().listAllColumns());
  }
 else {
    parser=new JsonStreamParser(ii.getDescriptor().listAllColumns());
  }
  Executors.newSingleThreadExecutor().submit(consumer);
  final ExecutorService streamingBuilderPool=Executors.newFixedThreadPool(parallelism);
  for (int i=startShard; i < endShard; ++i) {
    final IIStreamBuilder task=new IIStreamBuilder(consumer.getStreamQueue(i % parallelism),streaming,iiSegment.getStorageLocationIdentifier(),iiSegment.getIIDesc(),i);
    task.setStreamParser(parser);
    if (i == endShard - 1) {
      streamingBuilderPool.submit(task).get();
    }
 else {
      streamingBuilderPool.submit(task);
    }
  }
}
