{
  Configuration conf=context.getConfiguration();
  intermediateTableRowDelimiter=conf.get(BatchConstants.CFG_CUBE_INTERMEDIATE_TABLE_ROW_DELIMITER,Character.toString(BatchConstants.INTERMEDIATE_TABLE_ROW_DELIMITER));
  byteRowDelimiter=intermediateTableRowDelimiter.getBytes("UTF-8")[0];
  bytesSplitter=new BytesSplitter(200,4096);
  KylinConfig config=AbstractHadoopJob.loadKylinPropsAndMetadata(conf);
  cubeName=conf.get(BatchConstants.CFG_CUBE_NAME);
  cube=CubeManager.getInstance(config).getCube(cubeName);
  cubeDesc=cube.getDescriptor();
  intermediateTableDesc=new JoinedFlatTableDesc(cubeDesc,null);
  long baseCuboidId=Cuboid.getBaseCuboidId(cubeDesc);
  Cuboid baseCuboid=Cuboid.findById(cubeDesc,baseCuboidId);
  List<TblColRef> columns=baseCuboid.getColumns();
  ArrayList<Integer> factDictCols=new ArrayList<Integer>();
  RowKeyDesc rowkey=cubeDesc.getRowkey();
  DictionaryManager dictMgr=DictionaryManager.getInstance(config);
  for (int i=0; i < columns.size(); i++) {
    TblColRef col=columns.get(i);
    if (rowkey.isUseDictionary(col) == false)     continue;
    String scanTable=(String)dictMgr.decideSourceData(cubeDesc,col,null)[0];
    if (cubeDesc.isFactTable(scanTable)) {
      factDictCols.add(i);
    }
  }
  this.factDictCols=new int[factDictCols.size()];
  for (int i=0; i < factDictCols.size(); i++)   this.factDictCols[i]=factDictCols.get(i);
}
