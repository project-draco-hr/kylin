{
  try {
    Map<String,Executable> runningJobs=context.getRunningJobs();
    if (runningJobs.size() >= jobEngineConfig.getMaxConcurrentJobLimit()) {
      logger.warn("There are too many jobs running, Job Fetch will wait until next schedule time");
      return;
    }
    int nRunning=0, nReady=0, nOthers=0, nError=0, nDiscarded=0, nSUCCEED=0;
    for (    final String id : executableManager.getAllJobIds()) {
      if (runningJobs.containsKey(id)) {
        nRunning++;
        continue;
      }
      final Output output=executableManager.getOutput(id);
      if ((output.getState() != ExecutableState.READY)) {
        if (output.getState() == ExecutableState.DISCARDED) {
          nDiscarded++;
        }
 else         if (output.getState() == ExecutableState.ERROR) {
          nError++;
        }
 else         if (output.getState() == ExecutableState.SUCCEED) {
          nSUCCEED++;
        }
 else {
          nOthers++;
        }
        continue;
      }
      nReady++;
      AbstractExecutable executable=executableManager.getJob(id);
      String jobDesc=executable.toString();
      logger.info(jobDesc + " prepare to schedule");
      try {
        context.addRunningJob(executable);
        jobPool.execute(new JobRunner(executable));
        logger.info(jobDesc + " scheduled");
      }
 catch (      Exception ex) {
        context.removeRunningJob(executable);
        logger.warn(jobDesc + " fail to schedule",ex);
      }
    }
    logger.info("Job Fetcher: " + nRunning + " should running, "+ runningJobs.size()+ " actual running, "+ nReady+ " ready, "+ nSUCCEED+ " already succeed, "+ nError+ " error, "+ nDiscarded+ " discarded, "+ nOthers+ " others");
  }
 catch (  Exception e) {
    logger.warn("Job Fetcher caught a exception " + e);
  }
}
