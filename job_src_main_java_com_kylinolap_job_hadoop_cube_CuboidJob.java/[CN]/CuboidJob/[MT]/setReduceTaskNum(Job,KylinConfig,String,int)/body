{
  Configuration jobConf=job.getConfiguration();
  KylinConfig kylinConfig=KylinConfig.getInstanceFromEnv();
  CubeDesc cubeDesc=CubeManager.getInstance(config).getCube(cubeName).getDescriptor();
  double perReduceInputMB=kylinConfig.getDefaultHadoopJobReducerInputMB();
  double reduceCountRatio=kylinConfig.getDefaultHadoopJobReducerCountRatio();
  double totalMapInputMB=this.getTotalMapInputMB();
  int preLevelCuboids, thisLevelCuboids;
  if (level == 0) {
    preLevelCuboids=thisLevelCuboids=1;
  }
 else {
    int[] allLevelCount=CuboidCLI.calculateAllLevelCount(cubeDesc);
    preLevelCuboids=allLevelCount[level - 1];
    thisLevelCuboids=allLevelCount[level];
  }
  double totalReduceInputMB=totalMapInputMB * thisLevelCuboids / preLevelCuboids;
  int numReduceTasks=(int)Math.round(totalReduceInputMB / perReduceInputMB * reduceCountRatio);
  if (cubeDesc.hasHolisticCountDistinctMeasures()) {
    numReduceTasks=numReduceTasks * 4;
  }
  numReduceTasks=Math.max(1,numReduceTasks);
  numReduceTasks=Math.min(kylinConfig.getHadoopJobMaxReducerNumber(),numReduceTasks);
  jobConf.setInt(MAPRED_REDUCE_TASKS,numReduceTasks);
  System.out.println("Having total map input MB " + Math.round(totalMapInputMB));
  System.out.println("Having level " + level + ", pre-level cuboids "+ preLevelCuboids+ ", this level cuboids "+ thisLevelCuboids);
  System.out.println("Having per reduce MB " + perReduceInputMB + ", reduce count ratio "+ reduceCountRatio);
  System.out.println("Setting " + MAPRED_REDUCE_TASKS + "="+ numReduceTasks);
}
