{
  String tableName=cubeSegment.getStorageLocationIdentifier();
  CubeInstance cubeInstance=cubeSegment.getCubeInstance();
  CubeDesc cubeDesc=cubeInstance.getDescriptor();
  KylinConfig kylinConfig=KylinConfig.getInstanceFromEnv();
  HTableDescriptor tableDesc=new HTableDescriptor(TableName.valueOf(cubeSegment.getStorageLocationIdentifier()));
  tableDesc.setValue(HTableDescriptor.SPLIT_POLICY,DisabledRegionSplitPolicy.class.getName());
  tableDesc.setValue(IRealizationConstants.HTableTag,kylinConfig.getMetadataUrlPrefix());
  tableDesc.setValue(IRealizationConstants.HTableCreationTime,String.valueOf(System.currentTimeMillis()));
  if (!StringUtils.isEmpty(kylinConfig.getKylinOwner())) {
    tableDesc.setValue(IRealizationConstants.HTableOwner,kylinConfig.getKylinOwner());
  }
  tableDesc.setValue(IRealizationConstants.HTableUser,cubeInstance.getOwner());
  Configuration conf=HBaseConfiguration.create();
  HBaseAdmin admin=new HBaseAdmin(conf);
  try {
    if (User.isHBaseSecurityEnabled(conf)) {
      tableDesc.addCoprocessor("org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint");
    }
    for (    HBaseColumnFamilyDesc cfDesc : cubeDesc.getHbaseMapping().getColumnFamily()) {
      HColumnDescriptor cf=new HColumnDescriptor(cfDesc.getName());
      cf.setMaxVersions(1);
      String hbaseDefaultCC=kylinConfig.getHbaseDefaultCompressionCodec().toLowerCase();
switch (hbaseDefaultCC) {
case "snappy":
{
          logger.info("hbase will use snappy to compress data");
          cf.setCompressionType(Algorithm.SNAPPY);
          break;
        }
case "lzo":
{
        logger.info("hbase will use lzo to compress data");
        cf.setCompressionType(Algorithm.LZO);
        break;
      }
case "gz":
case "gzip":
{
      logger.info("hbase will use gzip to compress data");
      cf.setCompressionType(Algorithm.GZ);
      break;
    }
case "lz4":
{
    logger.info("hbase will use lz4 to compress data");
    cf.setCompressionType(Algorithm.LZ4);
    break;
  }
default :
{
  logger.info("hbase will not user any compression codec to compress data");
}
}
cf.setDataBlockEncoding(DataBlockEncoding.FAST_DIFF);
cf.setInMemory(false);
cf.setBlocksize(4 * 1024 * 1024);
tableDesc.addFamily(cf);
}
if (admin.tableExists(tableName)) {
throw new RuntimeException("HBase table " + tableName + " exists!");
}
DeployCoprocessorCLI.deployCoprocessor(tableDesc);
admin.createTable(tableDesc,splitKeys);
Preconditions.checkArgument(admin.isTableAvailable(tableName),"table " + tableName + " created, but is not available due to some reasons");
logger.info("create hbase table " + tableName + " done.");
}
 catch (Exception e) {
logger.error("Failed to create HTable",e);
throw e;
}
 finally {
admin.close();
}
}
