{
  final CubeManager cubeManager=CubeManager.getInstance(context.getConfig());
  final CubeInstance cube=cubeManager.getCube(CubingExecutableUtil.getCubeName(this.getParams()));
  final CubeSegment segment=cube.getSegmentById(CubingExecutableUtil.getSegmentId(this.getParams()));
  List<CubeSegment> mergingSegs=cube.getMergingSegments(segment);
  Map<Integer,Long> mergedStartOffsets=Maps.newHashMap();
  Map<Integer,Long> mergedEndOffsets=Maps.newHashMap();
  long dateRangeStart=Long.MAX_VALUE, dateRangeEnd=0;
  for (  CubeSegment seg : mergingSegs) {
    Map<Integer,Long> startOffsets=KafkaOffsetMapping.parseOffsetStart(seg);
    Map<Integer,Long> endOffsets=KafkaOffsetMapping.parseOffsetEnd(seg);
    for (    Integer partition : startOffsets.keySet()) {
      long currentStart=mergedStartOffsets.get(partition) != null ? Long.valueOf(mergedStartOffsets.get(partition)) : Long.MAX_VALUE;
      long currentEnd=mergedEndOffsets.get(partition) != null ? Long.valueOf(mergedEndOffsets.get(partition)) : 0;
      mergedStartOffsets.put(partition,Math.min(currentStart,startOffsets.get(partition)));
      mergedEndOffsets.put(partition,Math.max(currentEnd,endOffsets.get(partition)));
    }
    dateRangeStart=Math.min(dateRangeStart,seg.getDateRangeStart());
    dateRangeEnd=Math.max(dateRangeEnd,seg.getDateRangeEnd());
  }
  KafkaOffsetMapping.saveOffsetStart(segment,mergedStartOffsets);
  KafkaOffsetMapping.saveOffsetEnd(segment,mergedEndOffsets);
  segment.setDateRangeStart(dateRangeStart);
  segment.setDateRangeEnd(dateRangeEnd);
  CubeUpdate cubeBuilder=new CubeUpdate(cube);
  cubeBuilder.setToUpdateSegs(segment);
  try {
    cubeManager.updateCube(cubeBuilder);
    return new ExecuteResult(ExecuteResult.State.SUCCEED,"succeed");
  }
 catch (  IOException e) {
    logger.error("fail to update cube segment offset",e);
    return new ExecuteResult(ExecuteResult.State.ERROR,e.getLocalizedMessage());
  }
}
