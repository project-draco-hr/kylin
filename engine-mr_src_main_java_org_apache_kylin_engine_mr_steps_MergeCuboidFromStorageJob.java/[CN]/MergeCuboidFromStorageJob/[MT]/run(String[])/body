{
  Options options=new Options();
  try {
    options.addOption(OPTION_JOB_NAME);
    options.addOption(OPTION_JOB_FLOW_ID);
    options.addOption(OPTION_CUBE_NAME);
    options.addOption(OPTION_SEGMENT_NAME);
    parseOptions(options,args);
    String cubeName=getOptionValue(OPTION_CUBE_NAME).toUpperCase();
    String segmentName=getOptionValue(OPTION_SEGMENT_NAME).toUpperCase();
    KylinConfig config=KylinConfig.getInstanceFromEnv();
    CubeManager cubeMgr=CubeManager.getInstance(config);
    CubeInstance cube=cubeMgr.getCube(cubeName);
    CubeSegment cubeSeg=cube.getSegment(segmentName,SegmentStatusEnum.NEW);
    Configuration conf=this.getConf();
    String jobName=getOptionValue(OPTION_JOB_NAME);
    System.out.println("Starting: " + jobName);
    job=Job.getInstance(conf,jobName);
    setJobClasspath(job);
    attachKylinPropsAndMetadata(cube,job.getConfiguration());
    job.getConfiguration().set(BatchConstants.CFG_CUBE_NAME,cubeName);
    job.getConfiguration().set(BatchConstants.CFG_CUBE_SEGMENT_NAME,segmentName);
    job.getConfiguration().set(BatchConstants.CFG_IS_MERGE,"true");
    IMRStorageInputFormat storageInputFormat=MRUtil.getBatchMergeInputSide2(cubeSeg).getStorageInputFormat();
    storageInputFormat.configureInput(MergeCuboidFromStorageMapper.class,ByteArrayWritable.class,ByteArrayWritable.class,job);
    IMRStorageOutputFormat storageOutputFormat=MRUtil.getBatchMergeOutputSide2(cubeSeg).getStorageOutputFormat();
    storageOutputFormat.configureOutput(InMemCuboidReducer.class,getOptionValue(OPTION_JOB_FLOW_ID),job);
    return waitForCompletion(job);
  }
 catch (  Exception e) {
    logger.error("error in MergeCuboidFromHBaseJob",e);
    printUsage(options);
    throw e;
  }
 finally {
    if (job != null)     cleanupTempConfFile(job.getConfiguration());
  }
}
