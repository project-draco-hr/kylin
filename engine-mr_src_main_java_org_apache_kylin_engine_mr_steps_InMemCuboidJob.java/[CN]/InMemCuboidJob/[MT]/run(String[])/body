{
  Options options=new Options();
  try {
    options.addOption(OPTION_JOB_NAME);
    options.addOption(OPTION_JOB_FLOW_ID);
    options.addOption(OPTION_CUBE_NAME);
    options.addOption(OPTION_SEGMENT_NAME);
    parseOptions(options,args);
    String cubeName=getOptionValue(OPTION_CUBE_NAME).toUpperCase();
    String segmentName=getOptionValue(OPTION_SEGMENT_NAME);
    KylinConfig config=KylinConfig.getInstanceFromEnv();
    CubeManager cubeMgr=CubeManager.getInstance(config);
    CubeInstance cube=cubeMgr.getCube(cubeName);
    CubeSegment cubeSeg=cube.getSegment(segmentName,SegmentStatusEnum.NEW);
    job=Job.getInstance(getConf(),getOptionValue(OPTION_JOB_NAME));
    logger.info("Starting: " + job.getJobName());
    setJobClasspath(job);
    attachKylinPropsAndMetadata(cube,job.getConfiguration());
    job.getConfiguration().set(BatchConstants.CFG_CUBE_NAME,cubeName);
    job.getConfiguration().set(BatchConstants.CFG_CUBE_SEGMENT_NAME,segmentName);
    long timeout=1000 * 60 * 60L;
    job.getConfiguration().set("mapred.task.timeout",String.valueOf(timeout));
    IMRTableInputFormat flatTableInputFormat=MRUtil.getBatchCubingInputSide(cubeSeg).getFlatTableInputFormat();
    flatTableInputFormat.configureJob(job);
    job.setMapperClass(InMemCuboidMapper.class);
    job.setMapOutputKeyClass(ByteArrayWritable.class);
    job.setMapOutputValueClass(ByteArrayWritable.class);
    IMRStorageOutputFormat storageOutputFormat=MRUtil.getBatchCubingOutputSide2(cubeSeg).getStorageOutputFormat();
    storageOutputFormat.configureOutput(InMemCuboidReducer.class,getOptionValue(OPTION_JOB_FLOW_ID),job);
    return waitForCompletion(job);
  }
 catch (  Exception e) {
    logger.error("error in CuboidJob",e);
    printUsage(options);
    throw e;
  }
 finally {
    if (job != null)     cleanupTempConfFile(job.getConfiguration());
  }
}
