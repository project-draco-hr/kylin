{
  String sampleTableName=factTableName + "_sample_1_of_" + sampleRatio;
  String settingQueries="set hive.exec.dynamic.partition.mode=nonstrict;set hive.exec.max.dynamic.partitions=10000;";
  String dropQuery="drop table if exists " + sampleTableName + ";";
  String createQuery="create table " + sampleTableName + " like "+ factTableName+ ";";
  HiveSourceTableMgmt hstm=new HiveSourceTableMgmt();
  File dir=File.createTempFile("meta",null);
  dir.delete();
  dir.mkdir();
  logger.info("Extracting table " + factTableName + "'s metadata into "+ dir.getAbsolutePath());
  hstm.extractTableDescWithTablePattern(factTableName,dir.getAbsolutePath());
  String factTableExdFilePath=dir.getAbsolutePath() + File.separator + HiveSourceTableMgmt.TABLE_EXD_FOLDER_NAME+ File.separator+ factTableName.toUpperCase()+ "."+ HiveSourceTableMgmt.OUTPUT_SURFIX;
  logger.info("Getting fact table's extend attributes from " + factTableExdFilePath);
  InputStream is=new FileInputStream(factTableExdFilePath);
  @SuppressWarnings("unchecked") Map<String,String> attrs=JsonUtil.readValue(is,HashMap.class);
  is.close();
  String partitionClause=getPartitionClause(attrs);
  String insertQuery=" INSERT OVERWRITE TABLE " + sampleTableName + " "+ partitionClause+ "  SELECT * FROM "+ factTableName+ " TABLESAMPLE(BUCKET 1 OUT OF "+ sampleRatio+ "  ON rand()) s;";
  String query=settingQueries + dropQuery + createQuery+ insertQuery;
  logger.info("The query being submitted is: \r\n" + query);
  is=HiveSourceTableMgmt.executeHiveCommand(query);
  InputStreamReader reader=new InputStreamReader(is);
  BufferedReader bufferedReader=new BufferedReader(reader);
  String line=null;
  while ((line=bufferedReader.readLine()) != null) {
    logger.info(line);
  }
  logger.info("end of the hive output stream");
  is.close();
  return sampleTableName;
}
